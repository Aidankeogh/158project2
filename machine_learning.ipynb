{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import json\n",
    "from random import shuffle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class nnEnsemble(object):\n",
    "    \"\"\"Neural network ensemble:\n",
    "    Passes the output of the input classifiers to a new multi-layer perceptron, that uses them as input params \n",
    "    \"\"\"\n",
    "    def __init__(self,classes):\n",
    "        self.pieces = classes\n",
    "        self.classifier = MLPClassifier(early_stopping=True,verbose=True)\n",
    "        \n",
    "    def transform(self,X):\n",
    "        feats = []\n",
    "        for x in X:\n",
    "            feat = []\n",
    "            for p in self.pieces:\n",
    "                feat += list(p.predict_proba(x)[0])\n",
    "            feats.append(feat)\n",
    "        return feats\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        feats = self.transform(X)\n",
    "        self.classifier.fit(feats,y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        feats = self.transform(X)\n",
    "        return self.classifier.predict(feats)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        feats = self.transform(X)\n",
    "        return self.classifier.predict_proba(feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakenews = []\n",
    "\n",
    "readfile = open(\"data/fakenews.json\",\"r\")\n",
    "for line in readfile:\n",
    "    article = json.loads(line)\n",
    "    fakenews.append(article[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "realnews = []\n",
    "readfile = open(\"data/realnews.json\",\"r\")\n",
    "for line in readfile:\n",
    "    article = json.loads(line)\n",
    "    if \"sports\" not in article[\"info\"][\"site_categories\"]:\n",
    "        realnews.append(article[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "realtest = realnews [int(len(realnews) * .9) :]\n",
    "faketest = fakenews [int(len(fakenews) * .9) :]\n",
    "realnews = realnews [: int(len(realnews) * .9)]\n",
    "fakenews = fakenews [: int(len(fakenews) * .9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"fake\"] * len(fakenews) + [\"real\"] * len(realnews)\n",
    "allnews = fakenews + realnews\n",
    "testlabels =  [\"fake\"] * len(faketest) + [\"real\"] * len(realtest)\n",
    "alltest = faketest + realtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features = 7500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectorizer.fit_transform(allnews)\n",
    "test_vec = vectorizer.transform(alltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGR = LogisticRegression()\n",
    "LGR.fit(vectors,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(vectors,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNB = MultinomialNB()\n",
    "MNB.fit(vectors,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.34206160\n",
      "Validation score: 0.933348\n",
      "Iteration 2, loss = 0.13662356\n",
      "Validation score: 0.954965\n",
      "Iteration 3, loss = 0.08991464\n",
      "Validation score: 0.958118\n",
      "Iteration 4, loss = 0.06684574\n",
      "Validation score: 0.960820\n",
      "Iteration 5, loss = 0.05231547\n",
      "Validation score: 0.964648\n",
      "Iteration 6, loss = 0.04229928\n",
      "Validation score: 0.961495\n",
      "Iteration 7, loss = 0.03425563\n",
      "Validation score: 0.964197\n",
      "Iteration 8, loss = 0.02829708\n",
      "Validation score: 0.961495\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP = MLPClassifier(early_stopping=True,verbose=True)\n",
    "MLP.fit(vectors,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.16443316\n",
      "Validation score: 0.996397\n",
      "Iteration 2, loss = 0.01623750\n",
      "Validation score: 0.997073\n",
      "Iteration 3, loss = 0.00828204\n",
      "Validation score: 0.998424\n",
      "Iteration 4, loss = 0.00537648\n",
      "Validation score: 0.998649\n",
      "Iteration 5, loss = 0.00393575\n",
      "Validation score: 0.999324\n",
      "Iteration 6, loss = 0.00313396\n",
      "Validation score: 0.999324\n",
      "Iteration 7, loss = 0.00267255\n",
      "Validation score: 0.999324\n",
      "Iteration 8, loss = 0.00237590\n",
      "Validation score: 0.999324\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "ENS = nnEnsemble([LGR,MNB,MLP,RFC])\n",
    "ENS.fit(vectors,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(classifier,text):\n",
    "    vec = vectorizer.transform([text])[0]\n",
    "    return classifier.predict(vec)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9584515606 0.962732919255 0.952868852459 0.957775489186\n",
      "0.892582083502 0.89397689769 0.888114754098 0.891036184211\n",
      "0.966558573166 0.974155898291 0.957786885246 0.965902045877\n",
      "0.951155249291 0.924681344148 0.981147540984 0.952077947902\n",
      "0.976489663559 0.971208434712 0.981557377049 0.976355483082\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for c in [LGR,MNB,MLP,RFC,ENS]:\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for t in faketest:\n",
    "        pred = predictor(c,t)\n",
    "        if pred == \"fake\":\n",
    "            tp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "    for t in realtest:\n",
    "        pred = predictor(c,t)\n",
    "        if pred == \"real\":\n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    precision = tp * 1.0/(tp + fp)\n",
    "    recall = tp * 1.0/(tp + fn)\n",
    "    acc = (tp+tn) * 1.0/(tp+tn+fp+fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    print acc, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_fake_str = \"\"\"Shock from the suicide-by-poisoning death of Bosnian Croat commander Slobodan Praljak at The Hague on Wednesday continues to reverberate as observers try to figure out how the military leader brought a bottle of poison into the courtroom. Speaking to Sputnik, one of his lawyers said she was shocked by what happened.\n",
    "The UN confirmed Wednesday that Praljak died in hospital after drinking what is thought to be a small bottle of poison in the courtroom, just hours after a judge handed down a 20-year jail sentence during an appeal hearing at the International Criminal Tribunal for the former Yugoslavia (ICTY). Praljak was charged for war crimes committed during the Bosnian War. The moment when he took the poison was captured on court cameras.\n",
    "\n",
    "Natasa Favo Ivanovic, one of Praljak's lawyers, offered insight into the details of Wednesday's deadly incident via a telephone interview with Sputnik Serbia.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shock from the suicide-by-poisoning death of Bosnian Croat commander Slobodan Praljak at The Hague on Wednesday continues to reverberate as observers try to figure out how the military leader brought a bottle of poison into the courtroom. Speaking to Sputnik, one of his lawyers said she was shocked by what happened.\n",
      "The UN confirmed Wednesday that Praljak died in hospital after drinking what is thought to be a small bottle of poison in the courtroom, just hours after a judge handed down a 20-year jail sentence during an appeal hearing at the International Criminal Tribunal for the former Yugoslavia (ICTY). Praljak was charged for war crimes committed during the Bosnian War. The moment when he took the poison was captured on court cameras.\n",
      "\n",
      "Natasa Favo Ivanovic, one of Praljak's lawyers, offered insight into the details of Wednesday's deadly incident via a telephone interview with Sputnik Serbia.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print manual_fake_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = vectorizer.transform([manual_fake_str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.8907798  0.1092202]]\n",
      "['fake']\n"
     ]
    }
   ],
   "source": [
    "print ENS.predict_proba(inputs)\n",
    "print ENS.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.962212313651 \t0.957461205341 \t0.966530054645 \t0.961974256708\n",
      "0.861910552628 \t0.820430804114 \t0.922723132969 \t0.86857559261\n",
      "0.99031662388 \t0.991732139594 \t0.988661202186 \t0.990194289884\n",
      "0.997793091024 \t0.995781930334 \t0.999772313297 \t0.997773132158\n",
      "0.999279376661 \t0.999316877676 \t0.999225865209 \t0.99927136937\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for c in [LGR,MNB,MLP,RFC,ENS]:\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for t in fakenews:\n",
    "        pred = predictor(c,t)\n",
    "        if pred == \"fake\":\n",
    "            tp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "    for t in realnews:\n",
    "        pred = predictor(c,t)\n",
    "        if pred == \"real\":\n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    precision = tp * 1.0/(tp + fp)\n",
    "    recall = tp * 1.0/(tp + fn)\n",
    "    acc = (tp+tn) * 1.0/(tp+tn+fp+fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    print acc,\"\\t\" ,precision,\"\\t\", recall,\"\\t\", f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
